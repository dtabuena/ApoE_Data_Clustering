{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObDAqqC4lPEl9KJbZ2RGnh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/ApoE_Data_Clustering/blob/main/MaxLikelihood_Hipp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oAeyWBUZbCIE"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl\n",
        "!pip install XlsxWriter\n",
        "!pip install pingouin\n",
        "!pip install CMH\n",
        "!pip install svgutils\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "\n",
        "clear_output()\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import pingouin as pg\n",
        "import scipy\n",
        "# from pandas.compat.numpy import np_array_datetime64_compat\n",
        "from random import sample\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "from google import colab\n",
        "\n",
        "\n",
        "!wget 'https://github.com/dtabuena/Resources/raw/refs/heads/main/Fonts/arial.ttf'\n",
        "mpl.font_manager.fontManager.addfont('/content/arial.ttf')\n",
        "\n",
        "clear_output()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def restore_order(arg_ord):\n",
        "    return np.argsort(arg_ord)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files(link):\n",
        "    my_drop_folder = 'my_drop_folder'\n",
        "    zipped_file_path = \"/content/\"+my_drop_folder + \".zip\"\n",
        "    unzipped_file_path = \"/content/\"+my_drop_folder\n",
        "    if not( os.path.exists(zipped_file_path)):\n",
        "        !wget -O $zipped_file_path $link    # download with new name\n",
        "    !echo A | unzip $zipped_file_path -d $unzipped_file_path\n",
        "    file_list = [f for r,d,f in os.walk(\"/content/\"+my_drop_folder )][0]\n",
        "    return file_list\n",
        "\n",
        "def read_data_file(xl_to_analyze):\n",
        "    my_df_dict  = pd.read_excel(xl_to_analyze, engine='openpyxl',index_col=None,sheet_name=None)\n",
        "    NEW_my_df_dict = {}\n",
        "    for k in my_df_dict.keys():\n",
        "        new_k = k\n",
        "        if 'cre' in new_k:\n",
        "            new_k = k.replace('Syn1-cre','/Syn1-Cre')\n",
        "        NEW_my_df_dict[new_k] = my_df_dict[k]\n",
        "\n",
        "    return NEW_my_df_dict, xl_to_analyze\n",
        "\n",
        "def dict_to_df(my_df_dict,AP_cut=60):\n",
        "    '''convert dict of categories into a DF'''\n",
        "    for k in my_df_dict.keys():\n",
        "        df = my_df_dict[k]\n",
        "        df['type'] = k\n",
        "    df_list = [my_df_dict[k] for k in my_df_dict.keys()]\n",
        "    full_df = pd.concat(df_list,ignore_index=True)\n",
        "\n",
        "    '''drop low AP amps'''\n",
        "    for r in full_df.index:\n",
        "        if full_df.loc[r,'AP amp'] <AP_cut:\n",
        "            full_df.at[r,'AP amp'] = np.nan\n",
        "    return full_df"
      ],
      "metadata": {
        "id": "pj62n1FKbKRL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Git clone data tables for sorting ###\n",
        "try: shutil.rmtree('./'+git_rep)\n",
        "except: None\n",
        "git_rep = 'Prelim_2023'\n",
        "git_link = 'https://github.com/dtabuena/'+git_rep+'/'\n",
        "!git clone $git_link\n",
        "file_list = [\n",
        "    os.path.join(root, file)\n",
        "    for root, dirs, files in os.walk('./' + git_rep + '/Cleaned_DataSets/')\n",
        "    for file in files\n",
        "    if file.endswith('.xlsx')\n",
        "]\n",
        "print(file_list)"
      ],
      "metadata": {
        "id": "9jD9L7LNbdQT",
        "outputId": "d6f0e2bc-300c-4fcf-e910-0c74a3951ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Prelim_2023'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 184 (delta 36), reused 0 (delta 0), pack-reused 114 (from 1)\u001b[K\n",
            "Receiving objects: 100% (184/184), 59.87 MiB | 14.62 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "['./Prelim_2023/Cleaned_DataSets/CA1 main parameters_Clean.xlsx', './Prelim_2023/Cleaned_DataSets/CA3 parameters for PCA_Clean.xlsx', './Prelim_2023/Cleaned_DataSets/DG Type II GC main parameters_Clean.xlsx', './Prelim_2023/Cleaned_DataSets/DG Type I GC main parameters_Clean.xlsx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# link = 'https://www.dropbox.com/sh/8gqut6sm8augo6p/AAD_jPpZFTFlaQlo6xOC5ENna?dl=0'\n",
        "# file_list = get_files(link)\n",
        "# file_list = [f for f in file_list if 'param' in f]\n",
        "# _ = [print(f) for f in file_list]"
      ],
      "metadata": {
        "id": "-vsBO3RIbPVa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIn9VsjUbfOs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "import statsmodels\n",
        "\n",
        "def MLR_FDR(full_df,cell_param_cols,key_list = ['genotype_key', 'age_key', 'combo_key' ]):\n",
        "    MLRT_df= pd.DataFrame(index=cell_param_cols)\n",
        "    for c in cell_param_cols:\n",
        "        y_full = full_df[c]\n",
        "        x_full = full_df[key_list]\n",
        "        x_full = sm.add_constant(x_full)\n",
        "        x_null = x_full['const']\n",
        "        full_model = sm.OLS(y_full, x_full,missing = 'drop').fit()\n",
        "        null_model = sm.OLS(y_full, x_null,missing = 'drop').fit()\n",
        "        full_ll = full_model.llf\n",
        "        null_ll = null_model.llf\n",
        "        LR_statistic = -2*(null_ll-full_ll)\n",
        "        p_val = scipy.stats.chi2.sf(LR_statistic, 2)\n",
        "        MLRT_df.at[c,'Full Model log-likelihood'] = full_ll\n",
        "        MLRT_df.at[c,'Null Model log-likelihood'] = null_ll\n",
        "        MLRT_df.at[c,'LR statistic'] = LR_statistic\n",
        "        MLRT_df.at[c,'p value'] = p_val\n",
        "    FDR = statsmodels.stats.multitest.fdrcorrection(MLRT_df['p value'],alpha=0.05)\n",
        "    MLRT_df['FDR corrected p'] = FDR[1]\n",
        "    MLRT_df['Hit'] = FDR[0]\n",
        "    return MLRT_df"
      ],
      "metadata": {
        "id": "SM-RAMBocIOs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def annotate_full_df(full_df, omit_cre=False,is_dg=False):\n",
        "    if 'fAHP(1)' in full_df.columns:\n",
        "        full_df['fAHP'] = full_df['fAHP(1)']\n",
        "        full_df.drop(labels='fAHP(1)',axis=1,inplace=True)\n",
        "\n",
        "    geno_list = full_df['type']\n",
        "    geno_list = [g.replace(' 7-9mo',\"\") for g in geno_list]\n",
        "    geno_list = [g.replace(' 17-19mo',\"\") for g in geno_list]\n",
        "    geno_list = [g.replace('type_1 ',\"\") for g in geno_list]\n",
        "    geno_list = [g.replace('type_2 ',\"\") for g in geno_list]\n",
        "    full_df['genotype'] = geno_list\n",
        "    full_df['genotype_key'] = [1 if 'E4' in g  else 0 for g in geno_list]\n",
        "\n",
        "    age_list = full_df['type']\n",
        "    age_list = [a.replace('apoE3-KI ',\"\") for a in age_list]\n",
        "    age_list = [a.replace('apoE4-KI ',\"\") for a in age_list]\n",
        "    age_list = [a.replace('fE4/Syn1-Cre- ',\"\") for a in age_list]\n",
        "    age_list = [a.replace('fE4/Syn1-Cre+ ',\"\") for a in age_list]\n",
        "    age_list = [a.replace('type_1 ',\"\") for a in age_list]\n",
        "    age_list = [a.replace('type_2 ',\"\") for a in age_list]\n",
        "    full_df['age'] = age_list\n",
        "    full_df['age_key'] = [1 if '17' in a  else 0 for a in age_list]\n",
        "\n",
        "    full_df['geno_age_inter'] = full_df['age_key']* 2 + full_df['genotype_key']\n",
        "    key_list = ['genotype_key','age_key','geno_age_inter']\n",
        "\n",
        "    if is_dg:\n",
        "        dgt_list = full_df['dg_type']\n",
        "        full_df['dgt_key'] = [1 if '2' in g  else 0 for g in geno_list]\n",
        "        full_df['type_age_inter'] = full_df['age_key']* 2 + full_df['dgt_key']\n",
        "        full_df['type_geno_inter'] = full_df['dgt_key']* 2 + full_df['genotype_key']\n",
        "        full_df['geno_age_inter'] = full_df['age_key']* 2 + full_df['genotype_key']\n",
        "        full_df['triple_inter'] = full_df['dgt_key']*4 +  full_df['age_key']* 2 + full_df['genotype_key']\n",
        "        key_list = ['genotype_key','age_key','dgt_key','type_age_inter','type_geno_inter','geno_age_inter','triple_inter']\n",
        "\n",
        "    if omit_cre: # omit cre\n",
        "        drop_rows = [i for i in full_df.index if 'Cre' in full_df.loc[i,'type']]\n",
        "        full_df.drop(drop_rows,axis = 0,inplace=True)\n",
        "    return full_df, key_list"
      ],
      "metadata": {
        "id": "hwd-a4cSmGCm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlrt_folder = 'mlrt_folder'\n",
        "os.makedirs('mlrt_folder', exist_ok=True)\n",
        "\n",
        "#### CA3 Group Stats\n",
        "_csv = [f for f in file_list if 'CA3' in f][0]\n",
        "my_df_dict, xl_to_analyze = read_data_file(_csv)\n",
        "full_df = dict_to_df(my_df_dict,AP_cut=60)\n",
        "full_df,key_list = annotate_full_df(full_df, omit_cre='True')\n",
        "labeling = ['cell','Cell','type','extra','age','dg_type','genotype'] + key_list\n",
        "cell_param_cols = [c for c in full_df.columns if c not in labeling ]\n",
        "ca3_MLRT_df = MLR_FDR(full_df,cell_param_cols,key_list)\n",
        "ca3_MLRT_df.to_csv(mlrt_folder+'/Ca3_MaxLikeRatio.csv')\n",
        "\n",
        "#### CA1 Group Stats\n",
        "_csv = [f for f in file_list if 'CA1' in f][0]\n",
        "my_df_dict, xl_to_analyze = read_data_file(_csv)\n",
        "full_df = dict_to_df(my_df_dict,AP_cut=60)\n",
        "full_df,key_list = annotate_full_df(full_df, omit_cre='True')\n",
        "labeling = ['cell','Cell','type','extra','age','dg_type','genotype'] + key_list\n",
        "cell_param_cols = [c for c in full_df.columns if c not in labeling ]\n",
        "ca1_MLRT_df = MLR_FDR(full_df,cell_param_cols,key_list)\n",
        "ca1_MLRT_df.to_csv(mlrt_folder+'/Ca1_MaxLikeRatio.csv')\n",
        "\n",
        "#### DG Group Stats\n",
        "_csv = [f for f in file_list if 'Type II' in f][0]\n",
        "typeII_my_df_dict, xl_to_analyze = read_data_file(_csv)\n",
        "typeII_df = dict_to_df(typeII_my_df_dict,AP_cut=60)\n",
        "typeII_df['dg_type']='type_2'\n",
        "for r in typeII_df.index: typeII_df.at[r,'type'] = 'type_2 '+ typeII_df.loc[r,'type']\n",
        "\n",
        "_csv = [f for f in file_list if 'Type I ' in f][0]\n",
        "typeI_my_df_dict, xl_to_analyze = read_data_file(_csv)\n",
        "typeI_df = dict_to_df(typeI_my_df_dict,AP_cut=60)\n",
        "typeI_df['dg_type']='type_1'\n",
        "for r in typeI_df.index: typeI_df.at[r,'type'] = 'type_1 '+ typeI_df.loc[r,'type']\n",
        "\n",
        "full_df = pd.concat([typeI_df,typeII_df],  axis=0, join='outer', ignore_index=True)\n",
        "full_df,key_list = annotate_full_df(full_df, omit_cre='True',is_dg=True)\n",
        "\n",
        "\n",
        "labeling = ['cell','Cell','type','extra','age','dg_type','genotype'] + key_list\n",
        "cell_param_cols = [c for c in full_df.columns if c not in labeling ]\n",
        "dg_MLRT_df = MLR_FDR(full_df,cell_param_cols,key_list)\n",
        "dg_MLRT_df.to_csv(mlrt_folder+'/DG_MaxLikeRatio.csv')"
      ],
      "metadata": {
        "id": "boChysglbUKL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import colab\n",
        "# colab.files.download( mlrt_folder+'/DG_MaxLikeRatio.csv' )\n",
        "# colab.files.download( mlrt_folder+'/Ca3_MaxLikeRatio.csv' )\n",
        "# colab.files.download( mlrt_folder+'/Ca1_MaxLikeRatio.csv' )\n",
        "zip_file = \"mlrt_folder.zip\"\n",
        "shutil.make_archive(\"mlrt_folder\", 'zip', mlrt_folder)\n",
        "colab.files.download(zip_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sd9W7wp2ejye",
        "outputId": "9cdaf946-fe26-46eb-dab6-5b27968a07b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de8821ee-a1ca-41a1-a2e1-34e33c9ccf18\", \"mlrt_folder.zip\", 3089)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}